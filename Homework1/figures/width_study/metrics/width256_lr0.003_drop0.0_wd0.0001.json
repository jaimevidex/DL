{
    "epochs": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30
    ],
    "train_losses": [
        3.256105422973633,
        0.6424167156219482,
        0.39553049206733704,
        0.3552659749984741,
        0.3321181535720825,
        0.31839519739151,
        0.3072338104248047,
        0.302152156829834,
        0.2945019602775574,
        0.29330208897590637,
        0.2879863679409027,
        0.2884039282798767,
        0.2832512855529785,
        0.28126540780067444,
        0.28078553080558777,
        0.27897846698760986,
        0.27914586663246155,
        0.2761699855327606,
        0.27514976263046265,
        0.2745469808578491,
        0.27450689673423767,
        0.27630236744880676,
        0.2709837257862091,
        0.2745446562767029,
        0.2700977623462677,
        0.2720657289028168,
        0.27077072858810425,
        0.27314236760139465,
        0.2699882388114929,
        0.2694157660007477,
        0.26892513036727905
    ],
    "valid_losses": [
        3.2562472820281982,
        0.44316503405570984,
        0.4013218879699707,
        0.3802456259727478,
        0.3964643180370331,
        0.36116108298301697,
        0.39220255613327026,
        0.3631269335746765,
        0.38877594470977783,
        0.3644334673881531,
        0.390344500541687,
        0.37022873759269714,
        0.38532590866088867,
        0.3835620582103729,
        0.3673349618911743,
        0.3555334806442261,
        0.378988116979599,
        0.37126728892326355,
        0.39125382900238037,
        0.3519408702850342,
        0.3593633472919464,
        0.36394861340522766,
        0.35712218284606934,
        0.3589552938938141,
        0.3580573797225952,
        0.3693636953830719,
        0.3799148201942444,
        0.3531549870967865,
        0.3670289218425751,
        0.35234999656677246,
        0.36048492789268494
    ],
    "train_accs": [
        0.04046154022216797,
        0.874673068523407,
        0.89432692527771,
        0.9024519324302673,
        0.9012211561203003,
        0.9120000004768372,
        0.9064422845840454,
        0.9124423265457153,
        0.9086538553237915,
        0.9119518995285034,
        0.9043076634407043,
        0.912865400314331,
        0.9079615473747253,
        0.9099038243293762,
        0.9138653874397278,
        0.9192115664482117,
        0.912990391254425,
        0.9169134497642517,
        0.9071345925331116,
        0.9206730723381042,
        0.9151250123977661,
        0.914307713508606,
        0.9210865497589111,
        0.9151827096939087,
        0.9165865182876587,
        0.9127404093742371,
        0.9113172888755798,
        0.9204711318016052,
        0.9167115092277527,
        0.9189423322677612,
        0.9179519414901733
    ],
    "valid_accs": [
        0.04139422997832298,
        0.8618749976158142,
        0.8764423131942749,
        0.8831250071525574,
        0.8779807686805725,
        0.8856731057167053,
        0.8783653974533081,
        0.8868749737739563,
        0.8809134364128113,
        0.885769248008728,
        0.8796153664588928,
        0.8862500190734863,
        0.8816345930099487,
        0.8800480961799622,
        0.8833172917366028,
        0.8899038434028625,
        0.8839904069900513,
        0.8877884745597839,
        0.8783172965049744,
        0.8908653855323792,
        0.8878365159034729,
        0.8867307901382446,
        0.8891345858573914,
        0.8864423036575317,
        0.8867307901382446,
        0.8864423036575317,
        0.8838461637496948,
        0.8914903998374939,
        0.8873077034950256,
        0.8878846168518066,
        0.8887500166893005
    ],
    "final_train_acc": 0.9179519414901733,
    "best_val_acc": 0.8914903998374939,
    "test_acc": 0.890096127986908,
    "config": {
        "batch_size": 64,
        "hidden_size": 256,
        "layers": 1,
        "learning_rate": 0.003,
        "l2_decay": 0.0001,
        "dropout": 0.0,
        "activation": "relu",
        "optimizer": "adam",
        "epochs": 30,
        "model": "width-256"
    }
}