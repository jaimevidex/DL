{
    "epochs": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30
    ],
    "train_losses": [
        3.262007713317871,
        1.2476837635040283,
        0.762256383895874,
        0.5997710824012756,
        0.5187165141105652,
        0.46530506014823914,
        0.4270668923854828,
        0.4009260833263397,
        0.38171255588531494,
        0.3641233444213867,
        0.3490220010280609,
        0.33613288402557373,
        0.32567036151885986,
        0.3157072961330414,
        0.3087848126888275,
        0.3004136085510254,
        0.29207727313041687,
        0.2853797376155853,
        0.2785283923149109,
        0.2733549177646637,
        0.2690255641937256,
        0.2658431828022003,
        0.2605157792568207,
        0.25678080320358276,
        0.2505103647708893,
        0.24830813705921173,
        0.242807999253273,
        0.2413526326417923,
        0.23832949995994568,
        0.23398587107658386,
        0.22987036406993866
    ],
    "valid_losses": [
        3.261838674545288,
        0.8472427129745483,
        0.6138377785682678,
        0.5058659315109253,
        0.44738849997520447,
        0.4126606285572052,
        0.38559475541114807,
        0.3672451674938202,
        0.3527045249938965,
        0.3410412073135376,
        0.33254480361938477,
        0.32936903834342957,
        0.3214940130710602,
        0.3176446855068207,
        0.31180673837661743,
        0.30878859758377075,
        0.30694180727005005,
        0.3044958710670471,
        0.3022248148918152,
        0.3030607998371124,
        0.29868748784065247,
        0.2984006106853485,
        0.30042144656181335,
        0.2964865565299988,
        0.2954125702381134,
        0.29158779978752136,
        0.2940903306007385,
        0.29563236236572266,
        0.29275184869766235,
        0.2923312485218048,
        0.2928287088871002
    ],
    "train_accs": [
        0.026221154257655144,
        0.7639999985694885,
        0.8296442031860352,
        0.8615865111351013,
        0.878125011920929,
        0.8891730904579163,
        0.898230791091919,
        0.9039615392684937,
        0.9097596406936646,
        0.9150577187538147,
        0.917471170425415,
        0.9194615483283997,
        0.9233173131942749,
        0.9260480999946594,
        0.9290480613708496,
        0.9306538701057434,
        0.932442307472229,
        0.9341154098510742,
        0.9354519248008728,
        0.9370961785316467,
        0.9379615187644958,
        0.9388942122459412,
        0.9402788281440735,
        0.9424231052398682,
        0.9437211751937866,
        0.9447596073150635,
        0.9445480704307556,
        0.9454423189163208,
        0.9474231004714966,
        0.948067307472229,
        0.9489327073097229
    ],
    "valid_accs": [
        0.026346154510974884,
        0.7609615325927734,
        0.8220192193984985,
        0.8525480628013611,
        0.8660095930099487,
        0.8764904141426086,
        0.8836538195610046,
        0.8887500166893005,
        0.8918269276618958,
        0.8957211375236511,
        0.8975480794906616,
        0.8990384340286255,
        0.9010096192359924,
        0.9023076891899109,
        0.9017307758331299,
        0.9033173322677612,
        0.9049038290977478,
        0.904567301273346,
        0.9062018990516663,
        0.9052884578704834,
        0.9062018990516663,
        0.9050480723381042,
        0.9069230556488037,
        0.9065384864807129,
        0.9078365564346313,
        0.9091826677322388,
        0.9072596430778503,
        0.9082692265510559,
        0.9092307686805725,
        0.9089903831481934,
        0.9077884554862976
    ],
    "final_train_acc": 0.9489327073097229,
    "best_val_acc": 0.9092307686805725,
    "test_acc": 0.9084134697914124,
    "config": {
        "batch_size": 64,
        "hidden_size": 256,
        "layers": 1,
        "learning_rate": 0.0003,
        "l2_decay": 0.0,
        "dropout": 0.2,
        "activation": "relu",
        "optimizer": "adam",
        "epochs": 30,
        "model": "width-256"
    }
}